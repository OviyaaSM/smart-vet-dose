{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b50abb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_dataset(n, seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    RBC = np.random.normal(6.5, 1.0, n).clip(4.0, 9.0)\n",
    "    WBC = np.random.normal(10, 3.0, n).clip(4.0, 18.0)\n",
    "    HB  = np.random.normal(13, 2.5, n).clip(7.0, 20.0)\n",
    "    Platelets = np.random.normal(300, 80, n).clip(100, 700)\n",
    "    Creatinine = np.random.normal(1.0, 0.3, n).clip(0.3, 2.5)\n",
    "    Glucose    = np.random.normal(100, 25, n).clip(50, 200)\n",
    "    Dose = np.random.uniform(0.3, 1.3, n)\n",
    "\n",
    "    Outcome = (\n",
    "        (HB > 12) &\n",
    "        (RBC > 5.5) &\n",
    "        (Creatinine < 1.3) &\n",
    "        (Dose < 1.0)\n",
    "    ).astype(int)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"RBC\": RBC,\n",
    "        \"WBC\": WBC,\n",
    "        \"HB\": HB,\n",
    "        \"Platelets\": Platelets,\n",
    "        \"Creatinine\": Creatinine,\n",
    "        \"Glucose\": Glucose,\n",
    "        \"Dose\": Dose,\n",
    "        \"Outcome\": Outcome\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85423ec9",
   "metadata": {},
   "source": [
    "**Notebook diagnostic:** Run the next code cell to show which Python executable this notebook kernel is using and whether numpy is importable. If numpy is missing, run the third cell to install it into this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d261333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook sys.executable: c:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Scripts\\python.exe\n",
      "Imported numpy, version: 2.3.5\n",
      "\n",
      "pip show numpy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['c:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\RP Model\\\\venv\\\\Scripts\\\\python.exe', '-m', 'pip', 'show', 'numpy'], returncode=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "print('Notebook sys.executable:', sys.executable)\n",
    "try:\n",
    "    import numpy as np\n",
    "    print('Imported numpy, version:', np.__version__)\n",
    "except Exception as e:\n",
    "    print('Import numpy failed:', repr(e))\n",
    "print('\\npip show numpy:')\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'show', 'numpy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8e6d1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing numpy into: c:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Scripts\\python.exe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell only if numpy is missing in the kernel above.\n",
    "import sys, subprocess\n",
    "print('Installing numpy into:', sys.executable)\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'numpy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "497dbb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "# Number of samples\n",
    "n = 1000\n",
    "\n",
    "# Simulate hematology parameters within realistic biological ranges\n",
    "RBC = np.random.normal(loc=6.5, scale=1.0, size=n).clip(4.0, 9.0)          # 4–9 ×10^6/µL\n",
    "WBC = np.random.normal(loc=10, scale=3.0, size=n).clip(4.0, 18.0)          # 4–18 ×10^3/µL\n",
    "HB  = np.random.normal(loc=13, scale=2.5, size=n).clip(7.0, 20.0)          # 7–20 g/dL\n",
    "Platelets = np.random.normal(loc=300, scale=80, size=n).clip(100, 700)     # 100–700 ×10^3/µL\n",
    "Creatinine = np.random.normal(loc=1.0, scale=0.3, size=n).clip(0.3, 2.5)   # 0.3–2.5 mg/dL\n",
    "Glucose    = np.random.normal(loc=100, scale=25, size=n).clip(50, 200)     # 50–200 mg/dL\n",
    "\n",
    "# Dose varies between low and high doses\n",
    "Dose = np.random.uniform(0.3, 1.3, n)\n",
    "\n",
    "# More realistic outcome rule (multifactor)\n",
    "Outcome = (\n",
    "    (HB > 12) & \n",
    "    (RBC > 5.5) &\n",
    "    (Creatinine < 1.3) &\n",
    "    (Dose < 1.0)\n",
    ").astype(int)\n",
    "\n",
    "# Construct dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"RBC\": RBC,\n",
    "    \"WBC\": WBC,\n",
    "    \"HB\": HB,\n",
    "    \"Platelets\": Platelets,\n",
    "    \"Creatinine\": Creatinine,\n",
    "    \"Glucose\": Glucose,\n",
    "    \"Dose\": Dose,\n",
    "    \"Outcome\": Outcome\n",
    "})\n",
    "\n",
    "df.head(), df.shape\n",
    "df.to_csv(\"smart_vet_dose_1000.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ade95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eca4c752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "accuracy_log = accuracy_score(y_test, y_pred)\n",
    "accuracy_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3518bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, rf_pred)\n",
    "accuracy_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a827b714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=4)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, xgb_pred)\n",
    "accuracy_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed45ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def evaluate_models(df):\n",
    "    X = df.drop(\"Outcome\", axis=1)\n",
    "    y = df[\"Outcome\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    lr_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "    results[\"Logistic Regression\"] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, lr_pred),\n",
    "        \"Precision\": precision_score(y_test, lr_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, lr_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_test, lr_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "\n",
    "    results[\"Random Forest\"] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, rf_pred),\n",
    "        \"Precision\": precision_score(y_test, rf_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, rf_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_test, rf_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "    # XGBoost\n",
    "    xgb = XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=4, use_label_encoder=False, eval_metric='logloss')\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "    results[\"XGBoost\"] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, xgb_pred),\n",
    "        \"Precision\": precision_score(y_test, xgb_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, xgb_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_test, xgb_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ca4f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:47:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:47:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:47:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:47:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:47:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:47:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:47:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Size</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.693548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>700</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.983871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.682081</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.634409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1250</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.805112</td>\n",
       "      <td>0.670270</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.652632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1250</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1250</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset Size                Model  Accuracy        F1  Precision    Recall\n",
       "0            400  Logistic Regression  0.740000  0.648649   0.615385  0.685714\n",
       "1            400        Random Forest  1.000000  1.000000   1.000000  1.000000\n",
       "2            400              XGBoost  1.000000  1.000000   1.000000  1.000000\n",
       "3            700  Logistic Regression  0.800000  0.710744   0.728814  0.693548\n",
       "4            700        Random Forest  1.000000  1.000000   1.000000  1.000000\n",
       "5            700              XGBoost  0.988571  0.983871   0.983871  0.983871\n",
       "6           1000  Logistic Regression  0.780000  0.682081   0.737500  0.634409\n",
       "7           1000        Random Forest  0.988000  0.983607   1.000000  0.967742\n",
       "8           1000              XGBoost  0.984000  0.978022   1.000000  0.956989\n",
       "9           1250  Logistic Regression  0.805112  0.670270   0.688889  0.652632\n",
       "10          1250        Random Forest  1.000000  1.000000   1.000000  1.000000\n",
       "11          1250              XGBoost  1.000000  1.000000   1.000000  1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run experiments for different dataset sizes\n",
    "import pandas as pd\n",
    "\n",
    "dataset_sizes = [400, 700, 1000, 1250]\n",
    "final_results = []\n",
    "\n",
    "for size in dataset_sizes:\n",
    "    df = generate_dataset(size)\n",
    "    model_results = evaluate_models(df)\n",
    "\n",
    "    for model, metrics in model_results.items():\n",
    "        final_results.append({\n",
    "            \"Dataset Size\": size,\n",
    "            \"Model\": model,\n",
    "            **metrics\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(final_results)\n",
    "# Pivot for nicer display\n",
    "results_df_pivot = results_df.pivot_table(index=[\"Dataset Size\", \"Model\"], values=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"]).reset_index()\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(\"model_results.csv\", index=False)\n",
    "\n",
    "results_df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb8c578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Size</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.693548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>700</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.983871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.682081</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.634409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1250</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.805112</td>\n",
       "      <td>0.670270</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.652632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1250</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1250</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset Size                Model  Accuracy        F1  Precision    Recall\n",
       "0            400  Logistic Regression  0.740000  0.648649   0.615385  0.685714\n",
       "1            400        Random Forest  1.000000  1.000000   1.000000  1.000000\n",
       "2            400              XGBoost  1.000000  1.000000   1.000000  1.000000\n",
       "3            700  Logistic Regression  0.800000  0.710744   0.728814  0.693548\n",
       "4            700        Random Forest  1.000000  1.000000   1.000000  1.000000\n",
       "5            700              XGBoost  0.988571  0.983871   0.983871  0.983871\n",
       "6           1000  Logistic Regression  0.780000  0.682081   0.737500  0.634409\n",
       "7           1000        Random Forest  0.988000  0.983607   1.000000  0.967742\n",
       "8           1000              XGBoost  0.984000  0.978022   1.000000  0.956989\n",
       "9           1250  Logistic Regression  0.805112  0.670270   0.688889  0.652632\n",
       "10          1250        Random Forest  1.000000  1.000000   1.000000  1.000000\n",
       "11          1250              XGBoost  1.000000  1.000000   1.000000  1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show results summary\n",
    "import pandas as pd\n",
    "results_df = pd.read_csv(\"model_results.csv\")\n",
    "results_df_pivot = results_df.pivot_table(index=[\"Dataset Size\", \"Model\"], values=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\"]).reset_index()\n",
    "results_df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35024b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick numeric summary of results\n",
    "import pandas as pd\n",
    "results_df = pd.read_csv('model_results.csv')\n",
    "print('Rows:', len(results_df))\n",
    "print(results_df.groupby('Model')['Accuracy'].agg(['mean','min','max']).round(3))\n",
    "results_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
