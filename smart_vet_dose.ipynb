{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50abb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85423ec9",
   "metadata": {},
   "source": [
    "**Notebook diagnostic:** Run the next code cell to show which Python executable this notebook kernel is using and whether numpy is importable. If numpy is missing, run the third cell to install it into this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d261333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Generation Function\n",
    "def generate_dataset(n, seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    RBC = np.random.normal(6.5, 1.0, n).clip(4.0, 9.0)\n",
    "    WBC = np.random.normal(10, 3.0, n).clip(4.0, 18.0)\n",
    "    HB  = np.random.normal(13, 2.5, n).clip(7.0, 20.0)\n",
    "    Platelets = np.random.normal(300, 80, n).clip(100, 700)\n",
    "    Creatinine = np.random.normal(1.0, 0.3, n).clip(0.3, 2.5)\n",
    "    Glucose    = np.random.normal(100, 25, n).clip(50, 200)\n",
    "    Dose = np.random.uniform(0.3, 1.3, n)\n",
    "\n",
    "    # Probabilistic risk score\n",
    "    risk_score = (\n",
    "        0.2 * (HB / 20) +\n",
    "        0.15 * (RBC / 9) -\n",
    "        0.2 * (Creatinine / 2.5) -\n",
    "        0.1 * (Dose / 1.3)\n",
    "    )\n",
    "\n",
    "    # Biological noise - increased for better distribution\n",
    "    risk_score += np.random.normal(0, 0.15, n)\n",
    "\n",
    "    # Sigmoid probability with better threshold\n",
    "    prob_safe = 1 / (1 + np.exp(-risk_score))\n",
    "\n",
    "    Outcome = (prob_safe > 0.5).astype(int)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"RBC\": RBC,\n",
    "        \"WBC\": WBC,\n",
    "        \"HB\": HB,\n",
    "        \"Platelets\": Platelets,\n",
    "        \"Creatinine\": Creatinine,\n",
    "        \"Glucose\": Glucose,\n",
    "        \"Dose\": Dose,\n",
    "        \"Outcome\": Outcome\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e6d1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 8), (1250, 8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate datasets and save to CSV\n",
    "df_1000 = generate_dataset(1000, seed=1042)\n",
    "df_1250 = generate_dataset(1250, seed=1292)\n",
    "\n",
    "df_1000.to_csv(\"smart_vet_dose_1000.csv\", index=False)\n",
    "df_1250.to_csv(\"smart_vet_dose_1250.csv\", index=False)\n",
    "\n",
    "df_1000.shape, df_1250.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497dbb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation Function\n",
    "def evaluate_models(df):\n",
    "    X = df.drop(\"Outcome\", axis=1)\n",
    "    y = df[\"Outcome\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    lr_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "    results[\"Logistic Regression\"] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, lr_pred),\n",
    "        \"Precision\": precision_score(y_test, lr_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, lr_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_test, lr_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "\n",
    "    results[\"Random Forest\"] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, rf_pred),\n",
    "        \"Precision\": precision_score(y_test, rf_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, rf_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_test, rf_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "    # XGBoost\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "    results[\"XGBoost\"] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, xgb_pred),\n",
    "        \"Precision\": precision_score(y_test, xgb_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, xgb_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_test, xgb_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ade95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca4c752",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m dataset_sizes:\n\u001b[32m      6\u001b[39m     df = generate_dataset(size, seed=\u001b[32m42\u001b[39m + size)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     model_results = \u001b[43mevaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m model, metrics \u001b[38;5;129;01min\u001b[39;00m model_results.items():\n\u001b[32m     10\u001b[39m         final_results.append({\n\u001b[32m     11\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDataset Size\u001b[39m\u001b[33m\"\u001b[39m: size,\n\u001b[32m     12\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m     13\u001b[39m             **metrics\n\u001b[32m     14\u001b[39m         })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mevaluate_models\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Logistic Regression\u001b[39;00m\n\u001b[32m     17\u001b[39m lr = LogisticRegression(max_iter=\u001b[32m1000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mlr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m lr_pred = lr.predict(X_test_scaled)\n\u001b[32m     21\u001b[39m results[\u001b[33m\"\u001b[39m\u001b[33mLogistic Regression\u001b[39m\u001b[33m\"\u001b[39m] = {\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m\"\u001b[39m: accuracy_score(y_test, lr_pred),\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPrecision\u001b[39m\u001b[33m\"\u001b[39m: precision_score(y_test, lr_pred, zero_division=\u001b[32m0\u001b[39m),\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRecall\u001b[39m\u001b[33m\"\u001b[39m: recall_score(y_test, lr_pred, zero_division=\u001b[32m0\u001b[39m),\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mF1\u001b[39m\u001b[33m\"\u001b[39m: f1_score(y_test, lr_pred, zero_division=\u001b[32m0\u001b[39m)\n\u001b[32m     26\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\OneDrive\\Desktop\\RP Model\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1335\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1333\u001b[39m classes_ = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_classes < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1335\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1336\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis solver needs samples of at least 2 classes\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1337\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m in the data, but the data contains only one\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1338\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % classes_[\u001b[32m0\u001b[39m]\n\u001b[32m   1339\u001b[39m     )\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.classes_) == \u001b[32m2\u001b[39m:\n\u001b[32m   1342\u001b[39m     n_classes = \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(1)"
     ]
    }
   ],
   "source": [
    "#Final Evaluation Loop (Run this cell to evaluate models on different dataset sizes)\n",
    "dataset_sizes = [400, 700, 1000, 1250]\n",
    "final_results = []\n",
    "\n",
    "for size in dataset_sizes:\n",
    "    df = generate_dataset(size, seed=42 + size)\n",
    "    model_results = evaluate_models(df)\n",
    "\n",
    "    for model, metrics in model_results.items():\n",
    "        final_results.append({\n",
    "            \"Dataset Size\": size,\n",
    "            \"Model\": model,\n",
    "            **metrics\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(final_results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3518bd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Save Results to CSV and Pivot Table\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mresults_df\u001b[49m.to_csv(\u001b[33m\"\u001b[39m\u001b[33mmodel_results.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      4\u001b[39m results_df_pivot = results_df.pivot_table(\n\u001b[32m      5\u001b[39m     index=[\u001b[33m\"\u001b[39m\u001b[33mDataset Size\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m     values=[\u001b[33m\"\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPrecision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRecall\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mF1\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m ).reset_index()\n\u001b[32m      9\u001b[39m results_df_pivot\n",
      "\u001b[31mNameError\u001b[39m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Save Results to CSV and Pivot Table\n",
    "results_df.to_csv(\"model_results.csv\", index=False)\n",
    "\n",
    "results_df_pivot = results_df.pivot_table(\n",
    "    index=[\"Dataset Size\", \"Model\"],\n",
    "    values=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"]\n",
    ").reset_index()\n",
    "\n",
    "results_df_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a827b714",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Model Accuracy Summary\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mresults_df\u001b[49m.groupby(\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m\"\u001b[39m].agg([\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m]).round(\u001b[32m3\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Model Accuracy Summary\n",
    "results_df.groupby(\"Model\")[\"Accuracy\"].agg([\"mean\", \"min\", \"max\"]).round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed45ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix Visualization for Random Forest on 1000 Samples\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df = df_1000\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix â€” Random Forest (n=1000)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
